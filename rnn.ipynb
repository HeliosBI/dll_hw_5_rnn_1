{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преподаватель: Алексей Кузьмин, Алексей Миронов\n",
    "\n",
    "Задание 1.  \n",
    "Обучите нейронную сеть решать шифр цезаря.  \n",
    "Что надо сделать:  \n",
    "1.Написать алгоритм шифра цезаря для генерации выборки (сдвиг на К каждой буквы. Например, при сдвиге на 2 буква “А” переходит в букву “В” и тп)  \n",
    "2.Сделать нейронную сеть  \n",
    "3.Обучить ее (вход - зашифрованная фраза, выход - дешифрованная фраза)  \n",
    "4.Проверить качество  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Написать алгоритм шифра цезаря для генерации выборки (сдвиг на К каждой буквы. Например, при сдвиге на 2 буква “А” переходит в букву “В” и тп)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 13\n",
    "vocab = [char for char in 'АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ']\n",
    "\n",
    "\n",
    "def encrypt(text):\n",
    "    \"\"\"Returns the encrypted form of 'text'.\"\"\"\n",
    "    indexes = [vocab.index(char) for char in text]\n",
    "    encrypted_indexes = [(idx + key) % len(vocab) for idx in indexes]\n",
    "    encrypted_chars = [vocab[idx] for idx in encrypted_indexes]\n",
    "    encrypted = ''.join(encrypted_chars)\n",
    "    return encrypted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "МНОПРСТУФХЦЧШЩЪЫЬЭЮЯАБВГДЕЁЖЗИЙКЛ\n"
     ]
    }
   ],
   "source": [
    "print(encrypt('АБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 128\n",
    "message_length = 32\n",
    "\n",
    "\n",
    "def dataset(num_examples):\n",
    "    \"\"\"Returns a list of 'num_examples' pairs of the form (encrypted, original).\n",
    "\n",
    "    Both elements of the pair are tensors containing indexes of each character\n",
    "    of the corresponding encrypted or original message.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for x in range(num_examples):\n",
    "        ex_out = ''.join([random.choice(vocab) for x in range(message_length)])\n",
    "        # may be: MANR-TQNNAFEGIDE-OXQZANSVEMJXWSU\n",
    "        ex_in = encrypt(''.join(ex_out))\n",
    "        # may be: ZN-DMFC--NSRTVQRMAJCLN-EHRZWJIEG\n",
    "        ex_in = [vocab.index(x) for x in ex_in]\n",
    "        # may be: [25, 13, 26, 3, 12, 5, 2, 26, 26, ...\n",
    "        ex_out = [vocab.index(x) for x in ex_out]\n",
    "        # may be: [12, 0, 13, 17, 26, 19, 16, 13, ...\n",
    "        dataset.append([torch.tensor(ex_in), torch.tensor(ex_out)])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Сделать нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 10\n",
    "hidden_dim = 10\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "embed = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "linear = torch.nn.Linear(hidden_dim, vocab_size)\n",
    "softmax = torch.nn.functional.softmax\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(list(embed.parameters()) +\n",
    "                             list(lstm.parameters()) +\n",
    "                             list(linear.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_hidden():\n",
    "    return (torch.zeros(1, 1, hidden_dim),\n",
    "            torch.zeros(1, 1, hidden_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Обучить ее (вход - зашифрованная фраза, выход - дешифрованная фраза)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 3.0170\n",
      "Epoch: 1\n",
      "Loss: 2.1042\n",
      "Epoch: 2\n",
      "Loss: 1.1450\n",
      "Epoch: 3\n",
      "Loss: 0.6553\n",
      "Epoch: 4\n",
      "Loss: 0.2876\n",
      "Epoch: 5\n",
      "Loss: 0.1743\n",
      "Epoch: 6\n",
      "Loss: 0.0970\n",
      "Epoch: 7\n",
      "Loss: 0.0610\n",
      "Epoch: 8\n",
      "Loss: 0.0372\n",
      "Epoch: 9\n",
      "Loss: 0.0244\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "accuracies, max_accuracy = [], 0\n",
    "for x in range(num_epochs):\n",
    "    print('Epoch: {}'.format(x))\n",
    "    for encrypted, original in dataset(num_examples):\n",
    "        # encrypted.size() = [64]\n",
    "        lstm_in = embed(encrypted)\n",
    "        # lstm_in.size() = [64, 5]. This is a 2D tensor, but LSTM expects \n",
    "        # a 3D tensor. So we insert a fake dimension.\n",
    "        lstm_in = lstm_in.unsqueeze(1)\n",
    "        # lstm_in.size() = [64, 1, 5]\n",
    "        # Get outputs from the LSTM.\n",
    "        lstm_out, lstm_hidden = lstm(lstm_in, zero_hidden())\n",
    "        # lstm_out.size() = [64, 1, 10]\n",
    "        # Apply the affine transform.\n",
    "        scores = linear(lstm_out)\n",
    "        # scores.size() = [64, 1, 27], but loss_fn expects a tensor\n",
    "        # of size [64, 27, 1]. So we switch the second and third dimensions.\n",
    "        scores = scores.transpose(1, 2)\n",
    "        # original.size() = [64], but original should also be a 2D tensor\n",
    "        # of size [64, 1]. So we insert a fake dimension.\n",
    "        original = original.unsqueeze(1)\n",
    "        # Calculate loss.\n",
    "        loss = loss_fn(scores, original) \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "    print('Loss: {:6.4f}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Проверить качество "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        matches, total = 0, 0\n",
    "        for encrypted, original in dataset(num_examples):\n",
    "            lstm_in = embed(encrypted)\n",
    "            lstm_in = lstm_in.unsqueeze(1)\n",
    "            lstm_out, lstm_hidden = lstm(lstm_in, zero_hidden())\n",
    "            scores = linear(lstm_out)\n",
    "            # Compute a softmax over the outputs\n",
    "            predictions = softmax(scores, dim=2)\n",
    "            # Choose the letter with the maximum probability\n",
    "            _, batch_out = predictions.max(dim=2)\n",
    "            # Remove fake dimension\n",
    "            batch_out = batch_out.squeeze(1)\n",
    "            # Calculate accuracy\n",
    "            matches += torch.eq(batch_out, original).sum().item()\n",
    "            total += torch.numel(batch_out)\n",
    "        accuracy = matches / total\n",
    "        print('Accuracy: {:4.2f}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Задание 2.  \n",
    "Выполнить практическую работу из лекционного ноутбука.  \n",
    "а) построить RNN-ячейку на основе полносвязных слоев  \n",
    "б) применить построенную ячейку для генерации текста с выражениями героев сериала “Симпсоны”  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
